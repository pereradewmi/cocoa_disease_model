{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhanced Cocoa Disease Segmentation Model\n",
    "\n",
    "This notebook provides a comprehensive solution for cocoa disease segmentation with:\n",
    "- Fixed mask creation logic\n",
    "- Data validation and quality checks\n",
    "- Class balancing and proper metrics\n",
    "- Robust training pipeline\n",
    "- Enhanced inference and visualization\n",
    "\n",
    "## Key Improvements:\n",
    "1. **Fixed Binary Output Problem**: Proper multi-class segmentation (0, 1, 2, 3)\n",
    "2. **Enhanced Mask Processing**: Better overlap handling and validation\n",
    "3. **Class Balancing**: Handle imbalanced datasets effectively\n",
    "4. **Better Metrics**: IoU, F1-score, and detailed per-class evaluation\n",
    "5. **Robust Inference**: Post-processing and confidence scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Import our custom modules\n",
    "from data_validation import (\n",
    "    validate_mask_content, analyze_mask_directory, print_analysis_summary,\n",
    "    visualize_mask_samples, validate_image_mask_pairs\n",
    ")\n",
    "from model_utils import (\n",
    "    create_custom_metrics, calculate_class_weights, create_weighted_loss,\n",
    "    evaluate_model_detailed, print_evaluation_results, plot_confusion_matrix,\n",
    "    create_training_callbacks, plot_training_history\n",
    ")\n",
    "from inference import CocoaDiseasePredictor, print_prediction_summary\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(\"‚úÖ All modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "IMG_SIZE = (128, 128)\n",
    "NUM_CLASSES = 4  # background, healthy, black_pod_rot, pod_borer\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Data paths - Update these to your actual data paths\n",
    "BASE_DATA_DIR = '/content/drive/MyDrive/data'  # Update this path\n",
    "TRAIN_IMG_DIR = os.path.join(BASE_DATA_DIR, 'images/train')\n",
    "TRAIN_MASK_DIR = os.path.join(BASE_DATA_DIR, 'masks/train/Multiclass')\n",
    "VAL_IMG_DIR = os.path.join(BASE_DATA_DIR, 'images/val')\n",
    "VAL_MASK_DIR = os.path.join(BASE_DATA_DIR, 'masks/val/Multiclass')\n",
    "\n",
    "# Model save paths\n",
    "MODEL_SAVE_DIR = '/content/drive/MyDrive/models'  # Update this path\n",
    "os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n",
    "BEST_MODEL_PATH = os.path.join(MODEL_SAVE_DIR, 'enhanced_model.keras')\n",
    "\n",
    "print(f\"Configuration loaded:\")\n",
    "print(f\"  Image size: {IMG_SIZE}\")\n",
    "print(f\"  Number of classes: {NUM_CLASSES}\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Model will be saved to: {BEST_MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Fixed Mask Creation with Proper Overlap Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhanced_combine_masks(healthy_dir, black_pod_rot_dir, pod_borer_dir, output_dir, priority_order=None):\n",
    "    \"\"\"\n",
    "    Enhanced mask combination with proper overlap handling.\n",
    "    \n",
    "    Args:\n",
    "        healthy_dir: Directory containing healthy masks\n",
    "        black_pod_rot_dir: Directory containing black pod rot masks\n",
    "        pod_borer_dir: Directory containing pod borer masks\n",
    "        output_dir: Output directory for combined masks\n",
    "        priority_order: List defining class priority for overlaps [default: [3, 2, 1]]\n",
    "                       Higher priority classes override lower priority ones\n",
    "    \n",
    "    Returns:\n",
    "        dict: Processing results and statistics\n",
    "    \"\"\"\n",
    "    if priority_order is None:\n",
    "        priority_order = [3, 2, 1]  # pod_borer > black_pod_rot > healthy\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Find all mask files\n",
    "    mask_files = []\n",
    "    for ext in ['*.png', '*.jpg', '*.jpeg']:\n",
    "        mask_files.extend(glob.glob(os.path.join(healthy_dir, ext)))\n",
    "    \n",
    "    print(f\"üîç Found {len(mask_files)} mask files to process\")\n",
    "    \n",
    "    if len(mask_files) == 0:\n",
    "        print(f\"‚ö†Ô∏è  WARNING: No mask files found in {healthy_dir}\")\n",
    "        return {'error': 'No mask files found'}\n",
    "    \n",
    "    processing_stats = {\n",
    "        'total_processed': 0,\n",
    "        'successful': 0,\n",
    "        'errors': 0,\n",
    "        'overlap_cases': 0,\n",
    "        'class_distribution': Counter()\n",
    "    }\n",
    "    \n",
    "    for i, mask_path in enumerate(mask_files):\n",
    "        basename = os.path.basename(mask_path)\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(f\"  Processing {i+1}/{len(mask_files)}: {basename}\")\n",
    "        \n",
    "        try:\n",
    "            # Read individual class masks\n",
    "            healthy = cv2.imread(os.path.join(healthy_dir, basename), cv2.IMREAD_GRAYSCALE)\n",
    "            black_pod_rot = cv2.imread(os.path.join(black_pod_rot_dir, basename), cv2.IMREAD_GRAYSCALE)\n",
    "            pod_borer = cv2.imread(os.path.join(pod_borer_dir, basename), cv2.IMREAD_GRAYSCALE)\n",
    "            \n",
    "            if healthy is None:\n",
    "                print(f\"  ‚ö†Ô∏è  Warning: Couldn't read healthy mask {basename}\")\n",
    "                processing_stats['errors'] += 1\n",
    "                continue\n",
    "            \n",
    "            # Initialize combined mask with background (0)\n",
    "            combined_mask = np.zeros_like(healthy, dtype=np.uint8)\n",
    "            \n",
    "            # Create binary masks for each class\n",
    "            class_masks = {\n",
    "                1: healthy > 127 if healthy is not None else np.zeros_like(combined_mask, dtype=bool),\n",
    "                2: black_pod_rot > 127 if black_pod_rot is not None else np.zeros_like(combined_mask, dtype=bool),\n",
    "                3: pod_borer > 127 if pod_borer is not None else np.zeros_like(combined_mask, dtype=bool)\n",
    "            }\n",
    "            \n",
    "            # Check for overlaps\n",
    "            total_class_pixels = sum(np.sum(mask) for mask in class_masks.values())\n",
    "            union_pixels = np.sum(np.logical_or.reduce(list(class_masks.values())))\n",
    "            \n",
    "            if total_class_pixels > union_pixels:\n",
    "                processing_stats['overlap_cases'] += 1\n",
    "            \n",
    "            # Apply classes in priority order (lowest priority first)\n",
    "            for class_id in reversed(priority_order):\n",
    "                if class_id in class_masks:\n",
    "                    combined_mask[class_masks[class_id]] = class_id\n",
    "            \n",
    "            # Validate the combined mask\n",
    "            unique_values = np.unique(combined_mask)\n",
    "            if not set(unique_values).issubset({0, 1, 2, 3}):\n",
    "                print(f\"  ‚ö†Ô∏è  Warning: Invalid values in combined mask for {basename}: {unique_values}\")\n",
    "                # Clamp invalid values\n",
    "                combined_mask = np.clip(combined_mask, 0, 3)\n",
    "            \n",
    "            # Count class distribution\n",
    "            class_counts = Counter(combined_mask.flatten())\n",
    "            for class_id, count in class_counts.items():\n",
    "                processing_stats['class_distribution'][class_id] += count\n",
    "            \n",
    "            # Save combined mask\n",
    "            output_path = os.path.join(output_dir, os.path.splitext(basename)[0] + '.png')\n",
    "            cv2.imwrite(output_path, combined_mask)\n",
    "            \n",
    "            processing_stats['successful'] += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ùå Error processing {basename}: {e}\")\n",
    "            processing_stats['errors'] += 1\n",
    "        \n",
    "        processing_stats['total_processed'] += 1\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\n‚úÖ Mask combination completed:\")\n",
    "    print(f\"  Total processed: {processing_stats['total_processed']}\")\n",
    "    print(f\"  Successful: {processing_stats['successful']}\")\n",
    "    print(f\"  Errors: {processing_stats['errors']}\")\n",
    "    print(f\"  Overlap cases handled: {processing_stats['overlap_cases']}\")\n",
    "    \n",
    "    # Print class distribution\n",
    "    total_pixels = sum(processing_stats['class_distribution'].values())\n",
    "    if total_pixels > 0:\n",
    "        print(f\"\\nüìä Class distribution:\")\n",
    "        class_names = {0: 'Background', 1: 'Healthy', 2: 'Black Pod Rot', 3: 'Pod Borer'}\n",
    "        for class_id in sorted(processing_stats['class_distribution'].keys()):\n",
    "            count = processing_stats['class_distribution'][class_id]\n",
    "            percentage = (count / total_pixels) * 100\n",
    "            name = class_names.get(class_id, f'Class {class_id}')\n",
    "            print(f\"  {name}: {count:,} pixels ({percentage:.2f}%)\")\n",
    "    \n",
    "    return processing_stats\n",
    "\n",
    "# Only run mask combination if the multiclass directories don't exist or are empty\n",
    "if not os.path.exists(TRAIN_MASK_DIR) or len(os.listdir(TRAIN_MASK_DIR)) == 0:\n",
    "    print(\"üîß Creating enhanced multiclass masks for TRAINING data...\")\n",
    "    train_stats = enhanced_combine_masks(\n",
    "        healthy_dir=os.path.join(BASE_DATA_DIR, 'masks/train/healthy'),\n",
    "        black_pod_rot_dir=os.path.join(BASE_DATA_DIR, 'masks/train/black_pod_rot'),\n",
    "        pod_borer_dir=os.path.join(BASE_DATA_DIR, 'masks/train/pod_borer'),\n",
    "        output_dir=TRAIN_MASK_DIR\n",
    "    )\nelse:\n",
    "    print(f\"‚úÖ Training multiclass masks already exist in {TRAIN_MASK_DIR}\")\n",
    "\n",
    "if not os.path.exists(VAL_MASK_DIR) or len(os.listdir(VAL_MASK_DIR)) == 0:\n",
    "    print(\"\\nüîß Creating enhanced multiclass masks for VALIDATION data...\")\n",
    "    val_stats = enhanced_combine_masks(\n",
    "        healthy_dir=os.path.join(BASE_DATA_DIR, 'masks/val/healthy'),\n",
    "        black_pod_rot_dir=os.path.join(BASE_DATA_DIR, 'masks/val/black_pod_rot'),\n",
    "        pod_borer_dir=os.path.join(BASE_DATA_DIR, 'masks/val/pod_borer'),\n",
    "        output_dir=VAL_MASK_DIR\n",
    "    )\nelse:\n",
    "    print(f\"‚úÖ Validation multiclass masks already exist in {VAL_MASK_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Validation and Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate training masks\n",
    "print(\"üîç VALIDATING TRAINING MASKS\")\n",
    "print(\"=\"*50)\n",
    "train_mask_analysis = analyze_mask_directory(TRAIN_MASK_DIR, sample_size=100)\n",
    "print_analysis_summary(train_mask_analysis)\n",
    "\n",
    "# Validate validation masks  \n",
    "print(\"\\nüîç VALIDATING VALIDATION MASKS\")\n",
    "print(\"=\"*50)\n",
    "val_mask_analysis = analyze_mask_directory(VAL_MASK_DIR, sample_size=50)\n",
    "print_analysis_summary(val_mask_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate image-mask pairs\n",
    "print(\"üîç VALIDATING IMAGE-MASK PAIRS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "train_pair_validation = validate_image_mask_pairs(TRAIN_IMG_DIR, TRAIN_MASK_DIR, sample_size=10)\n",
    "val_pair_validation = validate_image_mask_pairs(VAL_IMG_DIR, VAL_MASK_DIR, sample_size=5)\n",
    "\n",
    "print(f\"\\nüìä Training pairs: {train_pair_validation.get('total_possible_pairs', 0)} total, {train_pair_validation.get('valid_pairs', 0)} valid\")\n",
    "print(f\"üìä Validation pairs: {val_pair_validation.get('total_possible_pairs', 0)} total, {val_pair_validation.get('valid_pairs', 0)} valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample masks to understand the data\n",
    "print(\"üé® Visualizing sample masks...\")\n",
    "visualize_mask_samples(TRAIN_MASK_DIR, num_samples=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Enhanced Data Loading with Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_enhanced_matching_paths(image_dir, mask_dir, image_exts=('jpg', 'jpeg', 'png'), mask_exts=('png',)):\n",
    "    \"\"\"Enhanced version with validation of matching image-mask pairs.\"\"\"\n",
    "    images = []\n",
    "    for ext in image_exts:\n",
    "        images += glob.glob(os.path.join(image_dir, f'*.{ext}'))\n",
    "\n",
    "    masks = []\n",
    "    for ext in mask_exts:\n",
    "        masks += glob.glob(os.path.join(mask_dir, f'*.{ext}'))\n",
    "\n",
    "    # Create dictionaries for matching\n",
    "    image_dict = {os.path.splitext(os.path.basename(p))[0]: p for p in images}\n",
    "    mask_dict = {os.path.splitext(os.path.basename(p))[0]: p for p in masks}\n",
    "\n",
    "    # Find common keys\n",
    "    common_keys = sorted(set(image_dict.keys()) & set(mask_dict.keys()))\n",
    "\n",
    "    matched_images = [image_dict[k] for k in common_keys]\n",
    "    matched_masks = [mask_dict[k] for k in common_keys]\n",
    "\n",
    "    print(f\"üìä Matched {len(matched_images)} image-mask pairs from {len(images)} images and {len(masks)} masks\")\n",
    "\n",
    "    if len(common_keys) == 0:\n",
    "        print(\"‚ùå WARNING: No matching image/mask pairs found!\")\n",
    "        print(\"Sample image keys:\", list(image_dict.keys())[:5])\n",
    "        print(\"Sample mask keys:\", list(mask_dict.keys())[:5])\n",
    "\n",
    "    return matched_images, matched_masks\n",
    "\n",
    "def enhanced_process_data(image_path, mask_path):\n",
    "    \"\"\"Enhanced data processing with validation.\"\"\"\n",
    "    # Load and process image\n",
    "    image = tf.io.read_file(image_path)\n",
    "    \n",
    "    # Try to decode as different formats\n",
    "    try:\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "    except:\n",
    "        try:\n",
    "            image = tf.image.decode_png(image, channels=3)\n",
    "        except:\n",
    "            # Last resort - try as any image format\n",
    "            image = tf.image.decode_image(image, channels=3)\n",
    "    \n",
    "    image = tf.image.resize(image, IMG_SIZE)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    \n",
    "    # Load and process mask\n",
    "    mask = tf.io.read_file(mask_path)\n",
    "    mask = tf.image.decode_png(mask, channels=1)\n",
    "    mask = tf.image.resize(mask, IMG_SIZE, method='nearest')\n",
    "    mask = tf.cast(mask, tf.int32)  # Keep as int32 for sparse_categorical_crossentropy\n",
    "    mask = tf.squeeze(mask, axis=-1)  # Remove channel dimension for sparse format\n",
    "    \n",
    "    # Validate mask values\n",
    "    mask = tf.clip_by_value(mask, 0, NUM_CLASSES-1)\n",
    "    \n",
    "    return image, mask\n",
    "\n",
    "def create_enhanced_dataset(image_dir, mask_dir, batch_size=8, shuffle=True, augment=False):\n",
    "    \"\"\"Create enhanced dataset with validation and optional augmentation.\"\"\"\n",
    "    image_paths, mask_paths = get_enhanced_matching_paths(image_dir, mask_dir)\n",
    "    \n",
    "    if len(image_paths) == 0:\n",
    "        print(\"‚ùå ERROR: No matching image/mask pairs found!\")\n",
    "        return None\n",
    "    \n",
    "    # Create dataset\n",
    "    image_ds = tf.data.Dataset.from_tensor_slices(image_paths)\n",
    "    mask_ds = tf.data.Dataset.from_tensor_slices(mask_paths)\n",
    "    \n",
    "    dataset = tf.data.Dataset.zip((image_ds, mask_ds))\n",
    "    dataset = dataset.map(enhanced_process_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    # Add data augmentation for training\n",
    "    if augment:\n",
    "        dataset = dataset.map(augment_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(1000)\n",
    "    \n",
    "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "def augment_data(image, mask):\n",
    "    \"\"\"Simple data augmentation that preserves mask integrity.\"\"\"\n",
    "    # Random horizontal flip\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        image = tf.image.flip_left_right(image)\n",
    "        mask = tf.image.flip_left_right(tf.expand_dims(mask, -1))\n",
    "        mask = tf.squeeze(mask, -1)\n",
    "    \n",
    "    # Random brightness adjustment (only for image)\n",
    "    image = tf.image.random_brightness(image, 0.1)\n",
    "    \n",
    "    # Random contrast adjustment (only for image)  \n",
    "    image = tf.image.random_contrast(image, 0.9, 1.1)\n",
    "    \n",
    "    # Ensure image values stay in [0, 1]\n",
    "    image = tf.clip_by_value(image, 0.0, 1.0)\n",
    "    \n",
    "    return image, mask\n",
    "\n",
    "# Create enhanced datasets\n",
    "print(\"üîß Creating enhanced datasets...\")\n",
    "train_dataset = create_enhanced_dataset(TRAIN_IMG_DIR, TRAIN_MASK_DIR, \n",
    "                                       batch_size=BATCH_SIZE, shuffle=True, augment=True)\n",
    "val_dataset = create_enhanced_dataset(VAL_IMG_DIR, VAL_MASK_DIR, \n",
    "                                     batch_size=BATCH_SIZE, shuffle=False, augment=False)\n",
    "\n",
    "if train_dataset is None or val_dataset is None:\n",
    "    print(\"‚ùå ERROR: Failed to create datasets. Please check your file paths and masks.\")\n",
    "else:\n",
    "    print(\"‚úÖ Enhanced datasets created successfully!\")\n",
    "    \n",
    "    # Quick validation of dataset contents\n",
    "    print(\"\\nüîç Validating dataset contents...\")\n",
    "    for images, masks in train_dataset.take(1):\n",
    "        print(f\"  Batch image shape: {images.shape}\")\n",
    "        print(f\"  Batch mask shape: {masks.shape}\")\n",
    "        print(f\"  Image value range: [{tf.reduce_min(images):.3f}, {tf.reduce_max(images):.3f}]\")\n",
    "        print(f\"  Mask unique values: {tf.unique(tf.reshape(masks, [-1]))[0].numpy()}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Calculate Class Weights for Balanced Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate class weights to handle imbalanced data\n",
    "print(\"‚öñÔ∏è  Calculating class weights for balanced training...\")\n",
    "class_weights = calculate_class_weights(TRAIN_MASK_DIR, num_classes=NUM_CLASSES, method='balanced')\n",
    "\n",
    "print(f\"\\nüìä Class weights will be used to balance training:\")\n",
    "class_names = ['Background', 'Healthy', 'Black Pod Rot', 'Pod Borer']\n",
    "for i, (class_id, weight) in enumerate(class_weights.items()):\n",
    "    print(f\"  {class_names[i]}: {weight:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Enhanced U-Net Model with Better Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_enhanced_unet(input_shape=(128, 128, 3), num_classes=4, dropout_rate=0.3):\n",
    "    \"\"\"\n",
    "    Build enhanced U-Net architecture with improvements:\n",
    "    - Batch normalization for stable training\n",
    "    - Dropout for regularization\n",
    "    - Skip connections for better gradient flow\n",
    "    \"\"\"\n",
    "    inputs = Input(input_shape, name='input_image')\n",
    "    \n",
    "    # Encoder (Contracting Path)\n",
    "    # Block 1\n",
    "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    c1 = tf.keras.layers.BatchNormalization()(c1)\n",
    "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
    "    c1 = tf.keras.layers.BatchNormalization()(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "    p1 = Dropout(dropout_rate)(p1)\n",
    "    \n",
    "    # Block 2\n",
    "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
    "    c2 = tf.keras.layers.BatchNormalization()(c2)\n",
    "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
    "    c2 = tf.keras.layers.BatchNormalization()(c2)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "    p2 = Dropout(dropout_rate)(p2)\n",
    "    \n",
    "    # Block 3\n",
    "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
    "    c3 = tf.keras.layers.BatchNormalization()(c3)\n",
    "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
    "    c3 = tf.keras.layers.BatchNormalization()(c3)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "    p3 = Dropout(dropout_rate)(p3)\n",
    "    \n",
    "    # Block 4\n",
    "    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(p3)\n",
    "    c4 = tf.keras.layers.BatchNormalization()(c4)\n",
    "    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(c4)\n",
    "    c4 = tf.keras.layers.BatchNormalization()(c4)\n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "    p4 = Dropout(dropout_rate)(p4)\n",
    "    \n",
    "    # Bridge (Bottleneck)\n",
    "    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)\n",
    "    c5 = tf.keras.layers.BatchNormalization()(c5)\n",
    "    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(c5)\n",
    "    c5 = tf.keras.layers.BatchNormalization()(c5)\n",
    "    c5 = Dropout(dropout_rate)(c5)\n",
    "    \n",
    "    # Decoder (Expansive Path)\n",
    "    # Block 6\n",
    "    u6 = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    u6 = Dropout(dropout_rate)(u6)\n",
    "    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(u6)\n",
    "    c6 = tf.keras.layers.BatchNormalization()(c6)\n",
    "    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(c6)\n",
    "    c6 = tf.keras.layers.BatchNormalization()(c6)\n",
    "    \n",
    "    # Block 7\n",
    "    u7 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    u7 = Dropout(dropout_rate)(u7)\n",
    "    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(u7)\n",
    "    c7 = tf.keras.layers.BatchNormalization()(c7)\n",
    "    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(c7)\n",
    "    c7 = tf.keras.layers.BatchNormalization()(c7)\n",
    "    \n",
    "    # Block 8\n",
    "    u8 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    u8 = Dropout(dropout_rate)(u8)\n",
    "    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(u8)\n",
    "    c8 = tf.keras.layers.BatchNormalization()(c8)\n",
    "    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(c8)\n",
    "    c8 = tf.keras.layers.BatchNormalization()(c8)\n",
    "    \n",
    "    # Block 9\n",
    "    u9 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "    u9 = concatenate([u9, c1])\n",
    "    u9 = Dropout(dropout_rate)(u9)\n",
    "    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(u9)\n",
    "    c9 = tf.keras.layers.BatchNormalization()(c9)\n",
    "    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(c9)\n",
    "    c9 = tf.keras.layers.BatchNormalization()(c9)\n",
    "    \n",
    "    # Output layer\n",
    "    outputs = Conv2D(num_classes, (1, 1), activation='softmax', name='segmentation_output')(c9)\n",
    "    \n",
    "    model = Model(inputs=[inputs], outputs=[outputs], name='enhanced_unet')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Build enhanced model\n",
    "print(\"üèóÔ∏è  Building enhanced U-Net model...\")\n",
    "model = build_enhanced_unet(input_shape=(*IMG_SIZE, 3), num_classes=NUM_CLASSES)\n",
    "\n",
    "# Create custom metrics\n",
    "custom_metrics = create_custom_metrics(NUM_CLASSES)\n",
    "\n",
    "# Create weighted loss function\n",
    "weighted_loss = create_weighted_loss(class_weights)\n",
    "\n",
    "# Compile model with enhanced configuration\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss=weighted_loss,\n",
    "    metrics=['accuracy'] + list(custom_metrics.values())\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Enhanced model compiled successfully!\")\n",
    "print(f\"üìä Model summary:\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Enhanced Training with Comprehensive Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training callbacks\n",
    "callbacks = create_training_callbacks(BEST_MODEL_PATH, patience=15)\n",
    "\n",
    "# Add additional monitoring\n",
    "callbacks.append(\n",
    "    tf.keras.callbacks.LearningRateScheduler(\n",
    "        lambda epoch: LEARNING_RATE * 0.95 ** epoch\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"üöÄ Starting enhanced training with {len(callbacks)} callbacks...\")\n",
    "print(f\"üìä Training configuration:\")\n",
    "print(f\"  Epochs: {EPOCHS}\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"  Class weights: {[f'{w:.3f}' for w in class_weights.values()]}\")\n",
    "print(f\"  Model will be saved to: {BEST_MODEL_PATH}\")\n",
    "\n",
    "# Train the model\n",
    "if train_dataset is not None and val_dataset is not None:\n",
    "    try:\n",
    "        history = model.fit(\n",
    "            train_dataset,\n",
    "            epochs=EPOCHS,\n",
    "            validation_data=val_dataset,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        print(\"\\n‚úÖ Training completed successfully!\")\n",
    "        \n",
    "        # Plot training history\n",
    "        plot_training_history(history, save_path=os.path.join(MODEL_SAVE_DIR, 'training_history.png'))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Training failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\nelse:\n",
    "    print(\"‚ùå Cannot start training: datasets not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Comprehensive Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model for evaluation\n",
    "if os.path.exists(BEST_MODEL_PATH):\n",
    "    print(f\"üìà Loading best model from: {BEST_MODEL_PATH}\")\n",
    "    best_model = tf.keras.models.load_model(BEST_MODEL_PATH, compile=False)\n",
    "    \n",
    "    # Recompile with metrics for evaluation\n",
    "    best_model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "        loss=weighted_loss,\n",
    "        metrics=['accuracy'] + list(custom_metrics.values())\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Best model loaded and compiled for evaluation\")\n",
    "    \n",
    "    # Perform detailed evaluation\n",
    "    if val_dataset is not None:\n",
    "        print(\"\\nüîç Performing detailed evaluation...\")\n",
    "        evaluation_results = evaluate_model_detailed(best_model, val_dataset, class_names)\n",
    "        \n",
    "        # Print detailed results\n",
    "        print_evaluation_results(evaluation_results, class_names)\n",
    "        \n",
    "        # Plot confusion matrix\n",
    "        plot_confusion_matrix(evaluation_results['confusion_matrix'], class_names)\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Validation dataset not available for evaluation\")\n",
    "        \nelse:\n",
    "    print(f\"‚ö†Ô∏è  Best model not found at: {BEST_MODEL_PATH}\")\n",
    "    print(\"Using the current model for evaluation...\")\n",
    "    best_model = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Enhanced Inference and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create enhanced predictor\n",
    "if os.path.exists(BEST_MODEL_PATH):\n",
    "    print(\"üîÆ Creating enhanced predictor...\")\n",
    "    predictor = CocoaDiseasePredictor(BEST_MODEL_PATH, input_size=IMG_SIZE)\n",
    "    print(\"‚úÖ Enhanced predictor created successfully!\")\n",
    "    \n",
    "    # Test on a validation image\n",
    "    if val_dataset is not None:\n",
    "        print(\"\\nüß™ Testing predictor on validation data...\")\n",
    "        \n",
    "        # Get a sample from validation dataset\n",
    "        for val_images, val_masks in val_dataset.take(1):\n",
    "            # Take first image from batch\n",
    "            sample_image = val_images[0].numpy()\n",
    "            sample_mask = val_masks[0].numpy()\n",
    "            \n",
    "            # Convert to correct format for predictor\n",
    "            sample_image_uint8 = (sample_image * 255).astype(np.uint8)\n",
    "            \n",
    "            # Make prediction\n",
    "            results = predictor.predict(sample_image_uint8, visualize=True)\n",
    "            \n",
    "            # Print detailed summary\n",
    "            print_prediction_summary(results)\n",
    "            \n",
    "            break\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Best model not available for enhanced inference\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Interactive Testing Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive testing function\n",
    "def test_uploaded_image():\n",
    "    \"\"\"Interactive function to test uploaded images.\"\"\"\n",
    "    try:\n",
    "        from google.colab import files\n",
    "        \n",
    "        print(\"üìÅ Upload an image to test the enhanced model:\")\n",
    "        uploaded = files.upload()\n",
    "        \n",
    "        if not uploaded:\n",
    "            print(\"No files uploaded!\")\n",
    "            return\n",
    "        \n",
    "        for filename in uploaded.keys():\n",
    "            print(f\"\\nüîç Analyzing: {filename}\")\n",
    "            print(\"=\"*50)\n",
    "            \n",
    "            # Predict using enhanced predictor\n",
    "            if os.path.exists(BEST_MODEL_PATH):\n",
    "                results = predictor.predict(filename, visualize=True)\n",
    "                print_prediction_summary(results)\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è  Enhanced predictor not available\")\n",
    "                \n",
    "    except ImportError:\n",
    "        print(\"üìù This interactive function is designed for Google Colab\")\n",
    "        print(\"For local testing, use: predictor.predict('path/to/image.jpg')\")\n",
    "\n",
    "# Create test interface\n",
    "print(\"üéÆ Enhanced testing interface ready!\")\n",
    "print(\"Call test_uploaded_image() to upload and test images\")\n",
    "\n",
    "# Uncomment the line below to start interactive testing\n",
    "# test_uploaded_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "### ‚úÖ Improvements Implemented:\n",
    "\n",
    "1. **Fixed Binary Output Problem**: \n",
    "   - Enhanced mask creation with proper overlap handling\n",
    "   - Data validation to ensure 4-class output (0, 1, 2, 3)\n",
    "   - Proper softmax activation for multi-class prediction\n",
    "\n",
    "2. **Enhanced Data Pipeline**:\n",
    "   - Comprehensive data validation utilities\n",
    "   - Improved image-mask pairing verification\n",
    "   - Data augmentation for better generalization\n",
    "\n",
    "3. **Better Model Training**:\n",
    "   - Class balancing with computed weights\n",
    "   - Enhanced U-Net with batch normalization and dropout\n",
    "   - Comprehensive metrics (IoU, Dice, per-class metrics)\n",
    "   - Improved callbacks and monitoring\n",
    "\n",
    "4. **Robust Inference Pipeline**:\n",
    "   - Post-processing with morphological operations\n",
    "   - Confidence scoring and uncertainty estimation\n",
    "   - Comprehensive visualization and analysis\n",
    "   - Disease severity assessment with recommendations\n",
    "\n",
    "### üéØ Expected Outcomes:\n",
    "- Model should now properly predict all 4 classes\n",
    "- Diseased pods correctly classified as black_pod_rot or pod_borer\n",
    "- More realistic training progression (not 100% accuracy immediately)\n",
    "- Better generalization with detailed per-class performance metrics\n",
    "\n",
    "### üöÄ Usage:\n",
    "```python\n",
    "# For single image prediction\n",
    "predictor = CocoaDiseasePredictor('enhanced_model.keras')\n",
    "results = predictor.predict('image.jpg')\n",
    "\n",
    "# For batch prediction\n",
    "batch_results = predictor.batch_predict(['img1.jpg', 'img2.jpg'])\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}